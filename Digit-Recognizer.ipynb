{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('digit_train.csv')\n",
    "test_df = pd.read_csv('digit_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = train_df['label']\n",
    "train_df = train_df.drop('label', axis=1)\n",
    "\n",
    "target.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    784.0\n",
       "mean       0.0\n",
       "std        0.0\n",
       "min        0.0\n",
       "25%        0.0\n",
       "50%        0.0\n",
       "75%        0.0\n",
       "max        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isna().sum().describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "32928000\n"
     ]
    }
   ],
   "source": [
    "test_df = test_df.iloc[:, :-1]\n",
    "print(test_df.shape)\n",
    "print(test_df.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noramlizing to a range of [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df / 255.0\n",
    "test_df = test_df / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.values.reshape(-1, 28, 28, 1)\n",
    "test_df = test_df.values.reshape(-1, 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = to_categorical(target, num_classes = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(train_df, target, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy88F64QAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAcLElEQVR4nO3df3DU9b3v8dcGyAqaLIaYbFICTRChFUhblJirUpQcQjyX4VdbUXsuOF440uApUqtNR0XanpMW77EevVTndFqo94oodwRGrsWDwYSxBjogDGVqU0LTEi8kVHqzG4KESD73D65bVxLtZ9nlnYTnY+Y7Q3a/73w/ft3hyZddvgk455wAALjI0qwXAAC4NBEgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgYrD1Aj6uu7tbR48eVUZGhgKBgPVyAACenHNqb29Xfn6+0tJ6v87pcwE6evSoCgoKrJcBALhAzc3NGjlyZK/P97kAZWRkSJJu0m0arCHGqwEA+PpAXXpTr8Z+P+9NygK0Zs0aPf7442ppaVFxcbGefvppTZky5VPnPvxrt8EaosEBAgQA/c7/v8Pop72NkpIPIbz44otasWKFVq5cqbffflvFxcUqLy/X8ePHU3E4AEA/lJIAPfHEE1q8eLHuvvtuff7zn9ezzz6rYcOG6ec//3kqDgcA6IeSHqAzZ85o7969Kisr++tB0tJUVlam+vr68/bv7OxUNBqN2wAAA1/SA/Tee+/p7Nmzys3NjXs8NzdXLS0t5+1fXV2tUCgU2/gEHABcGsz/IWpVVZUikUhsa25utl4SAOAiSPqn4LKzszVo0CC1trbGPd7a2qpwOHze/sFgUMFgMNnLAAD0cUm/AkpPT9fkyZNVU1MTe6y7u1s1NTUqLS1N9uEAAP1USv4d0IoVK7Rw4UJdd911mjJlip588kl1dHTo7rvvTsXhAAD9UEoCdPvtt+vPf/6zHn30UbW0tOgLX/iCtm3bdt4HEwAAl66Ac85ZL+KjotGoQqGQpmk2d0IAgH7oA9elWm1RJBJRZmZmr/uZfwoOAHBpIkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMpORu2EB/9f6cKd4zNWue8Z75/P9Y5j1T9J167xmgL+MKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa4GzZwgdIU8J6ZV+5/Z+v93/EeAfo0roAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBT4iLZF7d4zgwL+f457ad913jPXaI/3DNCXcQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqTARwwZdNZ75lT3Ge+Zz/3LCe8Z/5UBfRtXQAAAEwQIAGAi6QF67LHHFAgE4rbx48cn+zAAgH4uJe8BXXvttXr99df/epDBvNUEAIiXkjIMHjxY4XA4Fd8aADBApOQ9oEOHDik/P19FRUW66667dOTIkV737ezsVDQajdsAAANf0gNUUlKidevWadu2bXrmmWfU1NSkm2++We3t7T3uX11drVAoFNsKCgqSvSQAQB+U9ABVVFToq1/9qiZNmqTy8nK9+uqramtr00svvdTj/lVVVYpEIrGtubk52UsCAPRBKf90wPDhw3XNNdeosbGxx+eDwaCCwWCqlwEA6GNS/u+ATp48qcOHDysvLy/VhwIA9CNJD9ADDzyguro6/fGPf9Rbb72luXPnatCgQbrjjjuSfSgAQD+W9L+Ce/fdd3XHHXfoxIkTuuqqq3TTTTdp165duuqqq5J9KABAP5b0AG3YsCHZ3xLwlpaRkdDcPxT92numeOcS75mixv3eM8BAw73gAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATKf+BdICFln+YmNDcrZdv95756W9uS+hYwKWOKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4G7Y6PMCwaD3zH9d9kpCx/pxy995z4ysfiuhYwGXOq6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUfV7bV77oPXNvqD6hY4373//Ze2aMEjsWcKnjCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSHFRDbrySu+Zif/0G++Z33ed9p6RpGtWN3rPnE3oSAPP6VlTvGeOf9H/t6DCNb/znjl74i/eM0g9roAAACYIEADAhHeAdu7cqVmzZik/P1+BQECbN2+Oe945p0cffVR5eXkaOnSoysrKdOjQoWStFwAwQHgHqKOjQ8XFxVqzZk2Pz69evVpPPfWUnn32We3evVuXX365ysvLdfp0Yn8nDwAYmLzfAayoqFBFRUWPzznn9OSTT+rhhx/W7NmzJUnPPfeccnNztXnzZi1YsODCVgsAGDCS+h5QU1OTWlpaVFZWFnssFAqppKRE9fU9/9jizs5ORaPRuA0AMPAlNUAtLS2SpNzc3LjHc3NzY899XHV1tUKhUGwrKChI5pIAAH2U+afgqqqqFIlEYltzc7P1kgAAF0FSAxQOhyVJra2tcY+3trbGnvu4YDCozMzMuA0AMPAlNUCFhYUKh8OqqamJPRaNRrV7926VlpYm81AAgH7O+1NwJ0+eVGPjX29X0tTUpP379ysrK0ujRo3S8uXL9YMf/EBjx45VYWGhHnnkEeXn52vOnDnJXDcAoJ/zDtCePXt0yy23xL5esWKFJGnhwoVat26dHnzwQXV0dGjJkiVqa2vTTTfdpG3btumyyy5L3qoBAP1ewDnnrBfxUdFoVKFQSNM0W4MDQ6yXgyQbNLbIe+aV2v/lPXPzt77hPSNJGRt2JTTXV6VlZCQ01/DPn/ee2TfvSe+ZKwJB75klzVO9Z9694aT3DBL3getSrbYoEol84vv65p+CAwBcmggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC+8cxABei6Y6efzJusg0/8JeE5s4meR3JFLhugvfMrevqEzrW1ivrEpjyv7N1Iv4x9w3vmUd0fQpWggvFFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkeKi6hxz2ntmbuNt3jNn3znkPZOwQMB7pPGJEu+Z337tae+ZwRrkPSNJt/9hRkJzvl4s+g/vmQWvLPOeGavd3jNIPa6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAAT3IwUCTs11/+Gmgem/5v3zNcOzfOekXP+Mwl6b/EN3jO//9oa75kNJ8PeM89+5yveM5KU8eYfvGfeWVXof6Ai/5FAt//NX9E3cQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqRI2PvZ/n9+GRpI9575c8cV3jNZ3hPndN/8Re+Z1Q/9u/fM9veHes88P+dW75lh7+z2npGkjllTvGd2/P0T3jPHz3qPaNxP/uw9k8BhcBFwBQQAMEGAAAAmvAO0c+dOzZo1S/n5+QoEAtq8eXPc84sWLVIgEIjbZs6cmaz1AgAGCO8AdXR0qLi4WGvW9P4DtWbOnKljx47FthdeeOGCFgkAGHi8P4RQUVGhioqKT9wnGAwqHPb/6Y0AgEtHSt4Dqq2tVU5OjsaNG6elS5fqxIkTve7b2dmpaDQatwEABr6kB2jmzJl67rnnVFNTox/96Eeqq6tTRUWFzp7t+YOQ1dXVCoVCsa2goCDZSwIA9EFJ/3dACxYsiP164sSJmjRpksaMGaPa2lpNnz79vP2rqqq0YsWK2NfRaJQIAcAlIOUfwy4qKlJ2drYaGxt7fD4YDCozMzNuAwAMfCkP0LvvvqsTJ04oLy8v1YcCAPQj3n8Fd/LkybirmaamJu3fv19ZWVnKysrSqlWrNH/+fIXDYR0+fFgPPvigrr76apWXlyd14QCA/s07QHv27NEtt9wS+/rD928WLlyoZ555RgcOHNAvfvELtbW1KT8/XzNmzND3v/99BYPB5K0aANDveQdo2rRpcs71+vxrr712QQsCPi6wccRFO9ZfHuzwnpl62RnvmclP/KP3TN47b3nPDBqR2G1Z5/7wP7xnRg0e5j1z9WtLvGeu+f0e7xn0TdwLDgBgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACaS/iO5cekY1Ok/063e76TemxNf8J9JO3uD94wk/fIL/+o9M277P3nPjP1X/ztbDw7nes98+1fbvWckaUJ6u/fM+Ocf8J9ZdcB7ptt7An0VV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgImAc87/To8pFI1GFQqFNE2zNTgwxHo5SLJ/afq190yHS/eeGTv4pPeMJM3+zd3eM9mL2rxnjn1trPfM//y2/41Sxw8Jes9I0pf+2zLvmfCP/W+wioHpA9elWm1RJBJRZmZmr/txBQQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmBhsvQBcWr5Su9R7pnHGTxM40rAEZqStk9Z5z2x/c5T3zIIrXvOe+d5713nPvPpvU71nJCl/42+8Z7oTOhIuZVwBAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpLqqRryTwkpuR/HX0ZkTaUO+Zzwz+v94zZb+d6z0zbFGX90zW/6n3npG4sSguDq6AAAAmCBAAwIRXgKqrq3X99dcrIyNDOTk5mjNnjhoaGuL2OX36tCorKzVixAhdccUVmj9/vlpbW5O6aABA/+cVoLq6OlVWVmrXrl3avn27urq6NGPGDHV0dMT2uf/++/XKK69o48aNqqur09GjRzVv3rykLxwA0L95vSO8bdu2uK/XrVunnJwc7d27V1OnTlUkEtHPfvYzrV+/Xrfeeqskae3atfrc5z6nXbt26YYbbkjeygEA/doFvQcUiUQkSVlZWZKkvXv3qqurS2VlZbF9xo8fr1GjRqm+vudP43R2dioajcZtAICBL+EAdXd3a/ny5brxxhs1YcIESVJLS4vS09M1fPjwuH1zc3PV0tLS4/eprq5WKBSKbQUFBYkuCQDQjyQcoMrKSh08eFAbNmy4oAVUVVUpEonEtubm5gv6fgCA/iGhf4i6bNkybd26VTt37tTIkSNjj4fDYZ05c0ZtbW1xV0Gtra0Kh8M9fq9gMKhgMJjIMgAA/ZjXFZBzTsuWLdOmTZu0Y8cOFRYWxj0/efJkDRkyRDU1NbHHGhoadOTIEZWWliZnxQCAAcHrCqiyslLr16/Xli1blJGREXtfJxQKaejQoQqFQrrnnnu0YsUKZWVlKTMzU/fdd59KS0v5BBwAII5XgJ555hlJ0rRp0+IeX7t2rRYtWiRJ+vGPf6y0tDTNnz9fnZ2dKi8v109+8pOkLBYAMHAEnHPOehEfFY1GFQqFNE2zNTgwxHo5SLJAAu/3/f6n13rP7L3lv3vPSNLfPfYt75mcnf53+jh76A/eM0B/8YHrUq22KBKJKDMzs9f9uBccAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATCT0E1GBRLnOTu+Zsf/lbe+ZBfpP3jOSNEL13jNnEzoSAK6AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACa8AlRdXa3rr79eGRkZysnJ0Zw5c9TQ0BC3z7Rp0xQIBOK2e++9N6mLBgD0f14BqqurU2VlpXbt2qXt27erq6tLM2bMUEdHR9x+ixcv1rFjx2Lb6tWrk7poAED/N9hn523btsV9vW7dOuXk5Gjv3r2aOnVq7PFhw4YpHA4nZ4UAgAHpgt4DikQikqSsrKy4x59//nllZ2drwoQJqqqq0qlTp3r9Hp2dnYpGo3EbAGDg87oC+qju7m4tX75cN954oyZMmBB7/M4779To0aOVn5+vAwcO6KGHHlJDQ4NefvnlHr9PdXW1Vq1alegyAAD9VMA55xIZXLp0qX75y1/qzTff1MiRI3vdb8eOHZo+fboaGxs1ZsyY857v7OxUZ2dn7OtoNKqCggJN02wNDgxJZGkAAEMfuC7VaosikYgyMzN73S+hK6Bly5Zp69at2rlz5yfGR5JKSkokqdcABYNBBYPBRJYBAOjHvALknNN9992nTZs2qba2VoWFhZ86s3//fklSXl5eQgsEAAxMXgGqrKzU+vXrtWXLFmVkZKilpUWSFAqFNHToUB0+fFjr16/XbbfdphEjRujAgQO6//77NXXqVE2aNCkl/wEAgP7J6z2gQCDQ4+Nr167VokWL1NzcrK9//es6ePCgOjo6VFBQoLlz5+rhhx/+xL8H/KhoNKpQKMR7QADQT6XkPaBPa1VBQYHq6up8viUA4BLFveAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYGWy/g45xzkqQP1CU548UAALx9oC5Jf/39vDd9LkDt7e2SpDf1qvFKAAAXor29XaFQqNfnA+7TEnWRdXd36+jRo8rIyFAgEIh7LhqNqqCgQM3NzcrMzDRaoT3Owzmch3M4D+dwHs7pC+fBOaf29nbl5+crLa33d3r63BVQWlqaRo4c+Yn7ZGZmXtIvsA9xHs7hPJzDeTiH83CO9Xn4pCufD/EhBACACQIEADDRrwIUDAa1cuVKBYNB66WY4jycw3k4h/NwDufhnP50HvrchxAAAJeGfnUFBAAYOAgQAMAEAQIAmCBAAAAT/SZAa9as0Wc/+1lddtllKikp0a9//WvrJV10jz32mAKBQNw2fvx462Wl3M6dOzVr1izl5+crEAho8+bNcc875/Too48qLy9PQ4cOVVlZmQ4dOmSz2BT6tPOwaNGi814fM2fOtFlsilRXV+v6669XRkaGcnJyNGfOHDU0NMTtc/r0aVVWVmrEiBG64oorNH/+fLW2thqtODX+lvMwbdq0814P9957r9GKe9YvAvTiiy9qxYoVWrlypd5++20VFxervLxcx48ft17aRXfttdfq2LFjse3NN9+0XlLKdXR0qLi4WGvWrOnx+dWrV+upp57Ss88+q927d+vyyy9XeXm5Tp8+fZFXmlqfdh4kaebMmXGvjxdeeOEirjD16urqVFlZqV27dmn79u3q6urSjBkz1NHREdvn/vvv1yuvvKKNGzeqrq5OR48e1bx58wxXnXx/y3mQpMWLF8e9HlavXm204l64fmDKlCmusrIy9vXZs2ddfn6+q66uNlzVxbdy5UpXXFxsvQxTktymTZtiX3d3d7twOOwef/zx2GNtbW0uGAy6F154wWCFF8fHz4Nzzi1cuNDNnj3bZD1Wjh8/7iS5uro659y5//dDhgxxGzdujO3zzjvvOEmuvr7eapkp9/Hz4JxzX/7yl903v/lNu0X9Dfr8FdCZM2e0d+9elZWVxR5LS0tTWVmZ6uvrDVdm49ChQ8rPz1dRUZHuuusuHTlyxHpJppqamtTS0hL3+giFQiopKbkkXx+1tbXKycnRuHHjtHTpUp04ccJ6SSkViUQkSVlZWZKkvXv3qqurK+71MH78eI0aNWpAvx4+fh4+9Pzzzys7O1sTJkxQVVWVTp06ZbG8XvW5m5F+3HvvvaezZ88qNzc37vHc3Fz97ne/M1qVjZKSEq1bt07jxo3TsWPHtGrVKt188806ePCgMjIyrJdnoqWlRZJ6fH18+NylYubMmZo3b54KCwt1+PBhffe731VFRYXq6+s1aNAg6+UlXXd3t5YvX64bb7xREyZMkHTu9ZCenq7hw4fH7TuQXw89nQdJuvPOOzV69Gjl5+frwIEDeuihh9TQ0KCXX37ZcLXx+nyA8FcVFRWxX0+aNEklJSUaPXq0XnrpJd1zzz2GK0NfsGDBgtivJ06cqEmTJmnMmDGqra3V9OnTDVeWGpWVlTp48OAl8T7oJ+ntPCxZsiT264kTJyovL0/Tp0/X4cOHNWbMmIu9zB71+b+Cy87O1qBBg877FEtra6vC4bDRqvqG4cOH65prrlFjY6P1Usx8+Brg9XG+oqIiZWdnD8jXx7Jly7R161a98cYbcT++JRwO68yZM2pra4vbf6C+Hno7Dz0pKSmRpD71eujzAUpPT9fkyZNVU1MTe6y7u1s1NTUqLS01XJm9kydP6vDhw8rLy7NeipnCwkKFw+G410c0GtXu3bsv+dfHu+++qxMnTgyo14dzTsuWLdOmTZu0Y8cOFRYWxj0/efJkDRkyJO710NDQoCNHjgyo18OnnYee7N+/X5L61uvB+lMQf4sNGza4YDDo1q1b537729+6JUuWuOHDh7uWlhbrpV1U3/rWt1xtba1rampyv/rVr1xZWZnLzs52x48ft15aSrW3t7t9+/a5ffv2OUnuiSeecPv27XN/+tOfnHPO/fCHP3TDhw93W7ZscQcOHHCzZ892hYWF7v333zdeeXJ90nlob293DzzwgKuvr3dNTU3u9ddfd1/60pfc2LFj3enTp62XnjRLly51oVDI1dbWumPHjsW2U6dOxfa599573ahRo9yOHTvcnj17XGlpqSstLTVcdfJ92nlobGx03/ve99yePXtcU1OT27JliysqKnJTp041Xnm8fhEg55x7+umn3ahRo1x6erqbMmWK27Vrl/WSLrrbb7/d5eXlufT0dPeZz3zG3X777a6xsdF6WSn3xhtvOEnnbQsXLnTOnfso9iOPPOJyc3NdMBh006dPdw0NDbaLToFPOg+nTp1yM2bMcFdddZUbMmSIGz16tFu8ePGA+0NaT//9ktzatWtj+7z//vvuG9/4hrvyyivdsGHD3Ny5c92xY8fsFp0Cn3Yejhw54qZOneqysrJcMBh0V199tfv2t7/tIpGI7cI/hh/HAAAw0effAwIADEwECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgIn/Bxdtv+jpRXWrAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.imshow(x_train[0][:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convo2D Usage:\n",
    "1. In Convolutional Neural Networks (CNNs) for tasks like image classification, object detection, and image segmentation.\n",
    "2. At the beginning of the model to extract features from images (like edges, textures, etc.).\n",
    "\n",
    "# MaxPool2D Usage:\n",
    "1. After Conv2D layers to reduce the spatial dimensions of the feature maps while preserving the most important features.\n",
    "2. When you want to reduce the number of parameters and computational cost of the model.\n",
    "\n",
    "# Flatten\n",
    "1. This converts the 2D matrix of features into a 1D vector. This is necessary before feeding the data into fully connected (dense) layers, as these layers expect 1D input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "layer = Sequential()\n",
    "\n",
    "layer.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'Same', activation = 'relu', input_shape = (28,28,1)))\n",
    "layer.add(Conv2D(filters = 32, kernel_size = (5,5),padding = 'Same', activation ='relu'))\n",
    "layer.add(MaxPool2D(pool_size = (2, 2)))\n",
    "layer.add(Dropout(0.25))\n",
    "\n",
    "layer.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "layer.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', activation ='relu'))\n",
    "layer.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "layer.add(Dropout(0.25))\n",
    "\n",
    "layer.add(Flatten())\n",
    "layer.add(Dense(256, activation = \"relu\"))\n",
    "layer.add(Dropout(0.5))\n",
    "layer.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "optimizer = RMSprop(learning_rate = 0.001, rho = 0.9, epsilon = 1e-08)\n",
    "\n",
    "layer.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ReduceLROnPlateau is used to reduce the learning rate when there is no improve in the val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  374/33600 [..............................] - ETA: 1:09:16 - loss: 0.0775 - accuracy: 0.9770WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 33600 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 33600 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33600/33600 [==============================] - 50s 1ms/step - loss: 0.0775 - accuracy: 0.9770 - val_loss: 0.0266 - val_accuracy: 0.9913 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "model = layer.fit(datagen.flow(x_train, y_train, batch_size=90), epochs = 1, validation_data = (x_test, y_test), verbose = 1, steps_per_epoch=x_train.shape[0] , callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313/1313 [==============================] - 15s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "result =layer.predict(test_df)\n",
    "\n",
    "predicted_classes = np.argmax(result, axis=1)   # Convert probabilities to class labels\n",
    "\n",
    "results = pd.Series(predicted_classes,name=\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of predictions: 42000\n"
     ]
    }
   ],
   "source": [
    "# Assuming y_test is a DataFrame or Series containing the true labels\n",
    "print(f\"Number of predictions: {len(predicted_classes)}\")\n",
    "y_test = y_test.values if isinstance(y_test, pd.Series) else y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.992452380952381\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(target, predicted_classes)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
